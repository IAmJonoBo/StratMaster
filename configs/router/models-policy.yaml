---
tenants:
  default:
    tasks:
      reasoning:
        primary:
          provider: local
          model: mixtral-8x7b-instruct
          metadata:
            license: apache-2.0
            source: https://mistral.ai/news/mixtral-of-experts/
        fallbacks:
          - provider: local
            model: llama3-8b-instruct
            metadata:
              license: apache-2.0
              source: https://ai.meta.com/llama/
        parameters:
          max_output_tokens: 4096
          temperature_max: 0.8
      summarisation:
        primary:
          provider: local
          model: llama3-8b-instruct
          metadata:
            license: apache-2.0
            source: https://ai.meta.com/llama/
        fallbacks:
          - provider: local
            model: phi3-medium-instruct
            metadata:
              license: mit
              source: https://azure.microsoft.com/en-us/products/phi-3
        parameters:
          max_output_tokens: 2048
          temperature_max: 0.7
      embedding:
        primary:
          provider: local
          model: phi3-medium-embedding
          metadata:
            license: mit
            source: https://azure.microsoft.com/en-us/products/phi-3
        fallbacks:
          - provider: local
            model: nous-hermes2-embed
            metadata:
              license: apache-2.0
              source: https://huggingface.co/NousResearch/Nous-Hermes-2-Mistral-7B-DPO
        parameters:
          max_batch: 128
          allow_raw_documents: false
      rerank:
        primary:
          provider: local
          model: nous-hermes2-reranker
          metadata:
            license: apache-2.0
            source: https://huggingface.co/NousResearch/Nous-Hermes-2-Mistral-7B-DPO
        fallbacks:
          - provider: local
            model: phi3-medium-instruct
            metadata:
              license: mit
              source: https://azure.microsoft.com/en-us/products/phi-3
        parameters:
          max_candidates: 200
          score_threshold: 0.15
    providers:
      local:
        default: true
        models:
          - id: mixtral-8x7b-instruct
            license: apache-2.0
            usage: reasoning
          - id: llama3-8b-instruct
            license: apache-2.0
            usage: reasoning
          - id: phi3-medium-instruct
            license: mit
            usage: summarisation
          - id: phi3-medium-embedding
            license: mit
            usage: embedding
          - id: nous-hermes2-reranker
            license: apache-2.0
            usage: rerank
          - id: nous-hermes2-embed
            license: apache-2.0
            usage: embedding
      openai:
        enabled: false
        models:
          - gpt-large-reasoning
          - text-embedding-3-large
        egress:
          allow_domains:
            - api.openai.com
        privacy:
          send_raw_docs: false
          max_snippet_chars: 2000
        limits:
          tpm: 60000
          budget_usd_month: 100
    validation:
      reject_unknown_tasks: true
      enforce_privacy_constraints: true
      guardrails:
        temperature_max_global: 0.85
        max_context_tokens: 32000
    governance:
      allow_list:
        - mixtral-8x7b-instruct
        - llama3-8b-instruct
        - nous-hermes2-reranker
        - nous-hermes2-embed
        - phi3-medium-instruct
        - phi3-medium-embedding
      require_license_metadata: true
structured_outputs:
  enabled: true
  backend: outlines
  strict_json: true

# Sprint 4: Hybrid search configuration
hybrid_search:
  enabled: true
  fusion_weights:
    sparse: 0.3  # SPLADE/BM25 weight
    dense: 0.7   # Vector embedding weight
  field_boosts:
    title: 2.0
    abstract: 1.5
    content: 1.0
  retrieval_budget:
    max_passages: 50
    max_tokens: 8000
    disagreement_sampling:
      enabled: false  # Enable only when router policy indicates
      threshold: 0.3
  performance_targets:
    mrr_at_10_uplift: 0.20  # 20% improvement target
    max_latency_p95_ms: 500  # Must not degrade baseline performance
