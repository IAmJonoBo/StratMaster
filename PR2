PR-2 — feat(expertise-mcp): discipline evaluation server + API

Goal. Add a tenant-local MCP server that produces memos/votes with no network egress, wire new FastAPI endpoints, and expose spans/metrics. MCP gives us a standard tool/resource contract so agents can call expertise checks safely and portably.  ￼

File tree (new & modified)

packages/mcp-servers/expertise-mcp/
  pyproject.toml
  server.py
  tools.py
  schemas.py
  adapters/
    doctrine_loader.py
    checkers.py        # orchestrates discipline check functions
  tests/
    test_contracts.py
    test_evaluate_min.py
Dockerfile.expertise-mcp
docker-compose.yml               # (modified) new service + depends_on
helm/templates/
  expertise-mcp-deployment.yaml
  expertise-mcp-service.yaml
  expertise-mcp-networkpolicy.yaml
ops/policies/
  expertise-mcp-egress.rego
packages/api/routers/experts.py  # new FastAPI router
packages/orchestrator/graph/expert_council_node.py  # LangGraph node wrapper (MCP call)
packages/agents/experts/prompts/  # optional prompt snippets per discipline
tests/integration/
  test_expert_panel_flow.py

MCP server (Python) — minimal, production-safe skeleton

pyproject.toml

[project]
name = "expertise-mcp"
version = "0.1.0"
dependencies = [
  "mcp[python]>=1.0.0",      # official MCP SDK
  "pydantic>=2.6",
  "pyyaml>=6",
  "orjson>=3",
  "fastjsonschema>=2",
  "opentelemetry-sdk>=1.26.0",
  "opentelemetry-exporter-otlp>=1.26.0",
]

[tool.pyright]  # or mypy config
typeCheckingMode = "basic"

MCP is an open protocol with official multi-language SDKs; we depend on the Python SDK here for parity with the rest of your stack.  ￼

schemas.py

from packages.api.models.experts.memo import DisciplineMemo
from packages.api.models.experts.vote import CouncilVote

# expose pydantic JSON schemas for tool I/O
MEMO_SCHEMA = DisciplineMemo.model_json_schema()
VOTE_SCHEMA = CouncilVote.model_json_schema()

tools.py

from typing import Any
from packages.api.models.experts.memo import DisciplineMemo, Finding
from packages.api.models.experts.vote import CouncilVote, DisciplineVote
from .adapters.doctrine_loader import load_doctrines
from .adapters.checkers import run_checks_for_discipline

def evaluate(strategy: dict[str, Any], disciplines: list[str]) -> list[DisciplineMemo]:
    docs = load_doctrines()
    memos: list[DisciplineMemo] = []
    for d in disciplines:
        findings, scores, recs = run_checks_for_discipline(d, strategy, docs)
        memos.append(DisciplineMemo(
            id=f"memo:{d}",
            discipline=d,
            applies_to=strategy["id"],
            findings=[Finding(**f) for f in findings],
            scores=scores,
            recommendations=recs
        ))
    return memos

def vote(strategy_id: str, weights: dict[str, float], memos: list[DisciplineMemo]) -> CouncilVote:
    votes = []
    total, ws = 0.0, 0.0
    for m in memos:
        s = float(m.scores.get("overall", 0.0))
        w = float(weights.get(m.discipline, 0.0))
        votes.append(DisciplineVote(id=f"vote:{m.discipline}", discipline=m.discipline, score=s))
        total += s * w; ws += w
    return CouncilVote(id=f"vote:{strategy_id}", strategy_id=strategy_id, votes=votes,
                       weighted_score=(total/ws if ws>0 else 0.0), weights=weights)

server.py (MCP stdio)

import json, sys
from mcp.server import Server
from .schemas import MEMO_SCHEMA, VOTE_SCHEMA
from .tools import evaluate as _eval, vote as _vote

s = Server(name="expertise-mcp")

@s.tool(name="expert.evaluate", description="Run discipline checks and produce memos", schema={
  "type":"object","properties":{
    "strategy":{"type":"object"},
    "disciplines":{"type":"array","items":{"type":"string"}}
  },"required":["strategy","disciplines"]
})
def evaluate(strategy, disciplines):
    memos = _eval(strategy, disciplines)
    return [m.model_dump() for m in memos]

@s.tool(name="expert.vote", description="Aggregate memos into a weighted council vote", schema={
  "type":"object","properties":{
    "strategy_id":{"type":"string"},
    "weights":{"type":"object"},
    "memos":{"type":"array","items": MEMO_SCHEMA}
  },"required":["strategy_id","weights","memos"]
})
def _memo_adapter(memo):
    # If memo is a Pydantic model (has model_dump), use as-is; else wrap in adapter
    if hasattr(memo, "model_dump") and callable(memo.model_dump):
        return memo
    class MemoAdapter:
        def __init__(self, data):
            self._data = data
        def model_dump(self):
            return self._data
    return MemoAdapter(memo)

def vote(strategy_id, weights, memos):
    memos_objs = [_memo_adapter(m) for m in memos]  # tolerate raw dict input
    cv = _vote(strategy_id, weights, memos_objs)  # reusing our vote logic
    return cv.model_dump()

if __name__ == "__main__":
    s.run_stdio()  # no egress, runs inside tenant

This follows the MCP server pattern (stdio transport, declared tool schemas). Your orchestrator/agents call MCP tools, not raw HTTP, keeping network access policy-enforced and swappable.  ￼

FastAPI router

packages/api/routers/experts.py

from fastapi import APIRouter, Depends
from pydantic import BaseModel
from packages.api.models.experts.vote import CouncilVote
from packages.api.models.experts.memo import DisciplineMemo

router = APIRouter(prefix="/experts", tags=["experts"])

class EvaluateBody(BaseModel):
    strategy: dict
    disciplines: list[str] = ["psychology","design","communication","brand_science","economics"]

@router.post("/evaluate", response_model=list[DisciplineMemo])
async def evaluate(body: EvaluateBody, mcp=Depends(get_mcp_client)):
    return await mcp.call("expert.evaluate", body.model_dump())

class VoteBody(BaseModel):
    strategy_id: str
    weights: dict[str,float]
    memos: list[DisciplineMemo]

@router.post("/vote", response_model=CouncilVote)
async def vote(body: VoteBody, mcp=Depends(get_mcp_client)):
    return await mcp.call("expert.vote", body.model_dump())

We mount this router using FastAPI’s APIRouter pattern to keep modules clean and testable.  ￼

Orchestrator hook (LangGraph node)

packages/orchestrator/graph/expert_council_node.py (stub)

from langgraph.checkpoint import MemorySaver
# ... typical langgraph node pattern to call MCP and persist memos/vote into state

LangGraph gives us a durable, stateful agent graph; we add a new node after CoVe and before Adversary.  ￼

Helm / compose

helm/templates/expertise-mcp-networkpolicy.yaml — deny all egress; allow from orchestrator/API only.

ops/policies/expertise-mcp-egress.rego

package egress
default allow = false
allow {
  input.service == "expertise-mcp"
  input.dest == "localhost"     # local only
}

Tests
	•	Contract: MCP tool metadata includes JSON-Schema for inputs/outputs; round-trip a minimal memo/vote.
	•	Evaluate minimal: feed a toy strategy (missing proof → Design warns; reactance phrase → Psychology warns); confirm memo fields and severities.
	•	API smoke: POST /experts/evaluate returns memos; /experts/vote returns weighted score.

Acceptance criteria
	•	docker compose up expertise-mcp runs with no egress.
	•	New endpoints live and exercised in integration test; Langfuse gets spans (experts.evaluate, experts.vote).
	•	Council vote is stored with strategy artefacts; failures block Recommender (config thresholds from PR-1).
	•	Helm release includes Service/Deployment/NetworkPolicy; PR passes CI.

⸻

How this folds into StratMaster (sequence)
	1.	Merge PR-1 → models/configs/thresholds present; no runtime changes.
	2.	Merge PR-2 → new MCP server + API; orchestrator inserts Expert Council stage (after CoVe and before Adversary).
	3.	UI follow-up PR: Expert Panel tab, Persuasion Risk gauge, Message Map builder, Design Heuristics checker.

⸻

Ops & DX notes (short)
	•	Add make experts.schemas (runs schema generator + JSON lint) and make experts.mcp.up to spin expertise-mcp locally.
	•	Add Grafana chart panels for: council_score, reactance_risk, usability_pass_rate, wcag_pass_rate.
	•	Keep OpenAI provider/client off by default; if later routed, continue to require structured tool I/O and redaction. (Your existing provider gate remains consistent.)

⸻

Provenance (key refs)
	•	MCP spec & SDKs (protocol, stdio transport, multi-language SDKs).  ￼
	•	LangGraph (stateful agent orchestration; nodes/checkpoints).  ￼
	•	Pydantic v2 JSON-Schema/OpenAPI 3.1 emission.  ￼
	•	FastAPI APIRouter pattern for modular routers.  ￼
	•	NN/g 10 Usability Heuristics (Design rubric).  ￼
	•	WCAG 2.1/2.2 Quick Ref (AA subset for accessibility checks).  ￼
	•	EAST framework (Behavioural Insights Team).  ￼
	•	COM-B / Behaviour Change Wheel (Michie et al., Implementation Science).  ￼

⸻
