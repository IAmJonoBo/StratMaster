"""Composable governance workflow that stitches orchestration with decision assets."""

from __future__ import annotations

import importlib.util
import json
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any

from .ach import ACHMatrix, export_yaml, save_result, update_board
from .experiments import sequential_sprt
from .huggingface import DEFAULT_MODEL, HuggingFaceCritiqueEngine
from .planning import PlanBacklog, generate_epic_breakdown
from .premortem import PreMortemScenario, load_scenario, save_markdown
from .strategy import load_map, mermaid_diagram


def _load_orchestrator_components() -> tuple[Any, Any]:
    if importlib.util.find_spec("langgraph") is None:
        return None, None
    if importlib.util.find_spec("stratmaster_api") is None:
        return None, None
    from stratmaster_orchestrator.graph import build_strategy_graph  # type: ignore
    from stratmaster_orchestrator.state import StrategyState  # type: ignore

    return build_strategy_graph, StrategyState


@dataclass(slots=True)
class DecisionSupportBundle:
    """Aggregated artefacts generated by the governance pipeline."""

    query: str
    tenant_id: str
    ach_matrix: ACHMatrix | None
    premortem: PreMortemScenario | None
    orchestration_summary: dict[str, Any]
    planning_overview: str | None
    lead_time_summary: dict[str, int] | None
    wardley_mermaid: str | None
    experiment_notes: dict[str, str]
    huggingface_critiques: list[str]
    premortem_gaps: list[str]
    warnings: list[str] = field(default_factory=list)
    errors: list[str] = field(default_factory=list)

    def to_dict(self) -> dict[str, Any]:
        return {
            "query": self.query,
            "tenant_id": self.tenant_id,
            "orchestration": self.orchestration_summary,
            "ach": self.ach_matrix.to_dict() if self.ach_matrix else None,
            "premortem": self.premortem.to_dict() if self.premortem else None,
            "planning_overview": self.planning_overview,
            "lead_time_summary": self.lead_time_summary,
            "wardley_mermaid": self.wardley_mermaid,
            "experiment_notes": self.experiment_notes,
            "huggingface_critiques": self.huggingface_critiques,
            "premortem_gaps": self.premortem_gaps,
            "warnings": self.warnings,
            "errors": self.errors,
        }


def _summarise_orchestration(result: Any) -> dict[str, Any]:
    summary: dict[str, Any] = {}
    if result is None:
        return summary
    outcome = getattr(result, "outcome", None)
    state = getattr(result, "state", None)
    if outcome is not None:
        status = getattr(outcome, "status", None)
        summary["status"] = getattr(status, "value", status)
        summary["recommendation"] = getattr(outcome, "recommendation", None)
        summary["confidence"] = getattr(outcome, "confidence", None)
        debate = getattr(outcome, "debate", None)
        if debate is not None:
            turns = getattr(debate, "turns", [])
            summary["debate_turns"] = len(turns) if turns else 0
    if state is not None:
        summary["metrics"] = getattr(state, "metrics", {})
        summary["pending_tasks"] = getattr(state, "pending_tasks", [])
        summary["completed_tasks"] = getattr(state, "completed_tasks", [])
    return summary


def _load_ach(ach_path: Path | None, critique_level: str, errors: list[str]) -> ACHMatrix | None:
    if not ach_path:
        return None
    if not ach_path.exists():
        errors.append(f"ACH input not found: {ach_path}")
        return None
    payload = json.loads(ach_path.read_text(encoding="utf-8"))
    matrix = ACHMatrix.from_dict(payload)
    matrix.evaluate(critique_level=critique_level)
    return matrix


def _load_premortem(path: Path | None, errors: list[str]) -> PreMortemScenario | None:
    if not path:
        return None
    if not path.exists():
        errors.append(f"Pre-mortem input not found: {path}")
        return None
    return load_scenario(path)


def _derive_experiment_notes(matrix: ACHMatrix | None) -> dict[str, str]:
    if not matrix:
        return {}
    notes: dict[str, str] = {}
    verdict = matrix.decision.verdict.lower()
    verdict_id = None
    for hypothesis in matrix.hypotheses:
        if hypothesis.id.lower() in verdict or hypothesis.statement.lower() in verdict:
            verdict_id = hypothesis.id
            break
    if verdict_id:
        samples: list[bool] = []
        for evidence in matrix.evidence:
            decision = evidence.assessments.get(verdict_id, "unknown").lower()
            weight = max(1, int(round(evidence.weight)))
            if decision == "support":
                samples.extend([True] * weight)
            elif decision == "contradict":
                samples.extend([False] * weight)
        if samples:
            sprt_outcome = sequential_sprt(0.05, 0.2, 0.45, 0.6, samples)
            mapping = {
                "accept_alt": "Evidence supports proceeding; continue rollout with guardrails.",
                "accept_null": "Evidence contradicts the verdict; revisit hypotheses and guardrails.",
                "continue": "Collect additional evidence; sequential test has not converged.",
            }
            notes["sprt_recommendation"] = mapping.get(sprt_outcome, sprt_outcome)
            notes["sprt_sample_size"] = str(len(samples))
    coverage = 1.0
    if matrix.hypotheses:
        coverage -= len(matrix.consistency_warnings) / len(matrix.hypotheses)
    notes["consistency_coverage"] = f"{max(0.0, coverage):.2f}"
    return notes


def _load_planning(backlog_path: Path | None, errors: list[str]) -> tuple[str | None, dict[str, int] | None]:
    if not backlog_path or not backlog_path.exists():
        if backlog_path:
            errors.append(f"Planning backlog not found: {backlog_path}")
        return None, None
    backlog = PlanBacklog.load(backlog_path)
    return generate_epic_breakdown(backlog), backlog.lead_time_by_epic()


def _load_wardley(map_path: Path | None, errors: list[str]) -> str | None:
    if not map_path:
        return None
    if not map_path.exists():
        errors.append(f"Wardley map not found: {map_path}")
        return None
    map_payload = load_map(map_path)
    return mermaid_diagram(map_payload)


def run_decision_workflow(
    *,
    query: str,
    tenant_id: str,
    ach_path: Path | None = None,
    premortem_path: Path | None = None,
    critique_level: str = "standard",
    board_path: Path | None = None,
    ach_output_path: Path | None = None,
    ach_yaml_export: Path | None = None,
    premortem_markdown: Path | None = None,
    planning_backlog_path: Path | None = None,
    wardley_map_path: Path | None = None,
    huggingface_model: str | None = None,
) -> DecisionSupportBundle:
    errors: list[str] = []
    warnings: list[str] = []
    matrix = _load_ach(ach_path, critique_level, errors)
    premortem = _load_premortem(premortem_path, errors)

    build_graph, StrategyState = _load_orchestrator_components()
    orchestration_summary: dict[str, Any] = {}
    if build_graph and StrategyState:
        try:
            runner = build_graph()
            state = StrategyState(tenant_id=tenant_id, query=query)
            result = runner(state)
            orchestration_summary = _summarise_orchestration(result)
        except Exception as exc:  # pragma: no cover - integration safeguard
            errors.append(f"Orchestrator execution failed: {exc}")
    else:
        warnings.append("LangGraph or stratmaster_api dependencies unavailable; skipped orchestrator run.")

    planning_overview, lead_time_summary = _load_planning(planning_backlog_path, errors)
    wardley_mermaid = _load_wardley(wardley_map_path, errors)
    experiment_notes = _derive_experiment_notes(matrix)

    engine = HuggingFaceCritiqueEngine(model=huggingface_model or DEFAULT_MODEL)
    hf_critiques: list[str] = []
    if engine.available and (matrix or premortem):
        headline = f"Decision workflow for query: {query}"
        bullet_points: list[str] = []
        if matrix:
            bullet_points.append(
                f"ACH verdict: {matrix.decision.verdict} (confidence {matrix.decision.confidence})"
            )
            bullet_points.extend(matrix.critiques[:3])
        if premortem:
            bullet_points.append(f"Pre-mortem confidence: {premortem.confidence_score:.2f}")
            bullet_points.extend(premortem.identify_gaps()[:2])
        hf_critiques = engine.critique(headline, bullet_points)
        if matrix:
            matrix.extend_critiques(hf_critiques)
    elif not engine.available and huggingface_model:
        warnings.append("HuggingFace inference unavailable; skipped external critiques.")

    if matrix and ach_output_path:
        save_result(ach_output_path, matrix)
    if matrix and ach_yaml_export:
        export_yaml(ach_yaml_export, matrix)
    if matrix and board_path:
        update_board(board_path, matrix)
    if premortem and premortem_markdown:
        save_markdown(premortem_markdown, premortem)

    premortem_gaps = premortem.identify_gaps() if premortem else []

    bundle = DecisionSupportBundle(
        query=query,
        tenant_id=tenant_id,
        ach_matrix=matrix,
        premortem=premortem,
        orchestration_summary=orchestration_summary,
        planning_overview=planning_overview,
        lead_time_summary=lead_time_summary,
        wardley_mermaid=wardley_mermaid,
        experiment_notes=experiment_notes,
        huggingface_critiques=hf_critiques,
        premortem_gaps=premortem_gaps,
        warnings=warnings,
        errors=errors,
    )
    return bundle


__all__ = ["DecisionSupportBundle", "run_decision_workflow"]
