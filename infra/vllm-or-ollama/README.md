# vLLM/Ollama â€” Infra Stub

- Purpose: Local model serving for completions/embeddings; structured decoding.
- TODO: Models list; guided JSON config; resource sizing.
